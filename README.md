# Low Birth Weight Prediction Project (Python)

This project applies logistic regression to predict low infant birth weight based on maternal and prenatal variables using Python.

---

## ğŸ“ Project Structure

```
APM_low_infant_birth_wt_PY/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ birth_wt_clean.csv
â”‚   â”œâ”€â”€ processed/
â”‚   â”‚   â”œâ”€â”€ train_data.csv
â”‚   â”‚   â””â”€â”€ test_data.csv
â”œâ”€â”€ models/
â”‚   â””â”€â”€ logit_model.pkl
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ 01_modeling.ipynb
â”œâ”€â”€ outputs/
â”‚   â””â”€â”€ visualizations/
â”œâ”€â”€ .env
â””â”€â”€ README.md
```

---

## ğŸ§ª Objective

To predict whether an infant's birth weight is low using maternal characteristics and clinical data.

**Target Variable**:  
- `low` (1 = Low birth weight, 0 = Not low)

**Predictors**:  
- `age`: Motherâ€™s age  
- `lwt`: Weight at last menstrual period  
- `race`: (White, Black, Other)  
- `smoke`: Smoked during pregnancy  
- `ptl`: Premature labor history  
- `ht`: Hypertension history  
- `ui`: Uterine irritability  
- `ftv`: First trimester physician visits  

---

## ğŸ§¹ Data Processing

- Removed identifiers: `sr_no`, `id`
- Encoded categorical features
- Saved cleaned dataset to `processed/` directory

---

## ğŸ“Š Exploratory Data Analysis (EDA)

- Faceted visualizations were used to explore trends.
- Smoking, hypertension, and uterine irritability were linked to higher low birth weight risks.
- Distributions of age and weight (lwt) were examined for trends by target class.

---

## ğŸ§  Model Building

Model: Logistic Regression (via `sklearn`)  
Train-test split: 80/20 (random state 123)  
Performance measured on test set

---

## ğŸ“ˆ Evaluation

**Threshold Evaluation Summary**:

| Threshold | Sensitivity | Specificity | Misclassification |
|-----------|-------------|-------------|--------------------|
| 0.30      | 0.50        | 0.73        | 0.34               |
| 0.40      | 0.42        | 0.96        | 0.21               |
| 0.55      | 0.08        | 1.00        | 0.29               |

- **Recommended Cutoff**: 0.40 based on better trade-off between true positive and false positive rates in this test split.
- **ROC AUC Score**: 0.73 (Moderate discriminative power)

---

## ğŸ’¾ Model Saving

Trained model saved as `logit_model.pkl`:
```python
import joblib
joblib.dump(logit_model, 'models/logit_model.pkl')
```

---

## ğŸ§­ Insights

- Logistic regression yielded moderate accuracy.
- Feature `smoke`, `race`, and `ht` had stronger influence based on model coefficients.
- Threshold selection affected sensitivity and specificity balance.
- Results slightly differ from the R project due to different train-test partitions.

---

## ğŸ‘¨â€ğŸ’» Author

**William C. Phiri**  
ğŸ”— [GitHub](https://github.com/kochezz) | [LinkedIn](https://www.linkedin.com/in/william-phiri-866b8443/)

---

_Last updated: May 24, 2025_
